# Minimax search in Mancala

Minimax search is a fundamental depth-first search algorithm used in Artificial Intelligence, decision theory, game theory, and statistics.
The purpose of minimax search is to  **minimize the maximum loss** in a worst-case scenario - or, simply put, figure out the best action to pursue in a worst-case scenario.

This algorithm can be implemented in *n*-player games but is most commonly implemented in 2-player zero-sum games such as checkers, chess, connect 4, mancala, tic-tac-toe, etc.
Zero-sum games are simplified as turn-based games where one player wins and, as a result, the other player loses.

In this article we'll discuss what minimax search is, the related vocabulary, search tree structure and process, a basic example, and, finally, implement minimax in mancala.

---
## Minimax vocabulary

Let's familiarize ourselves with minimax-related variables and keywords before we implement minimax searches.

| **Keyword**       | **Variable**   | **Definition** |
| --------------    | -------------- | -------------- |
| Player/Maximizer  | p<sub>max</sub><sup>[1]</sup>| Maximizes their action's value and minimizes the maximum loss in a worst case scenario. |
 Opponent/Minimizer | p<sub>min</sub><sup>[1]</sup>| Minimizes the value of the player's (p<sub>max</sub>'s) action |
| Heuristic value   | `v`            | Value of the player's action - or current game state - obtained by an evaluation function. Larger numbers are more beneficial for p<sub>max</sub>, whereas smaller numbers are more benficial for p<sub>min</sub>. |
| Branching factor  | `b`            | How many actions the player has available |
| Depth             | `d`            | How deep into the tree - or how many moves ahead - the algorithm will search |

---
## Minimax tree structure

Suppose we're playing a 2-player turn-based game where each player has a choice between two actions per turn.
The branching factor, `b`, will be equal to 2.
We'll configure the algorithm to search to a depth of 3, which will set the variable `d` equal to 3.

Given the variables `b`=2 and `d`=3, the algorithm will generate the following tree structure:

<figure class="right">
    <p>
    <img src="img/minimax_tree.png" alt="Minimax tree structure"/>
    <figcaption>Tree generated by minimax with the branching factor of 2 and depth of 3.
    Each node in the tree is the value of a game state as a result of the player choosing an action.
 </figcaption>
</figure>

<!-- ![Minimax tree structure](img/minimax_tree.png) -->

The number of heuristic evaluations - also called *terminal nodes* or *leaf nodes*, seen in the figure as v1-v8 - completed in a minimax search tree is denoted by: **b<sup>d</sup>**.
It's important to notice that the size of the search tree increases exponentially based on **how deep the algorithm searches** and **how large the branching factor is**.

We have a mere 2<sup>3</sup> (8) heuristics evaluations in the tree above when looking 3 moves ahead.
However, the tree represents an arbitrary game for which there are only two possible actions per turn.

Consider chess, where the branching factor (possible moves) is exactly 20 for opening moves and about 35<sup>[2]</sup> for the remainder of the game.
If we re-configured our minimax algorithm's branching factor (`b`) to reflect the number of possible moves in chess, we would have to perform roughly 35<sup>3</sup> (42,875) heuristic evaluations.
And that's only looking 3 moves ahead!

The last thing to consider about these trees is that **the branching factor is not always uniform**.
Just because there are two possible moves this turn, it doesn't mean there will be two possible moves next turn.
Perhaps there is only one possible move next turn or you may have reached a terminal state where there are no possible moves; you've won or lost.

Looking at chess again: there are 20 possible opening moves, that is known.
After the first move, and depending on which piece is moved, there can be anywhere from 20-29 moves.
The opening move below allows for 29 possible moves on white's next turn - or 28 possible moves if black moves their pawn to d5.


<!-- ![29 possible moves for white](img/chess_opening_move.png) -->
<figure class="center">
    <img src="img/chess_opening_move.png" style="width:100%;">
    <figcaption>White's first move, pawn d2->d4, opens up an additional 9 moves for white's next turn</figcaption>
</figure>

---
## Minimax search

Recall that minimax search is a **depth-first search** algorithm; it starts at the root node and travels as deep as possible through each branch before backtracking to the top of the tree.
The depth-first search is complete once all nodes have been visited.

<figure class="right">
    <img src="img/depth_first_search.gif" style="width:100%;"/>
    <figcaption>Depth-first search on a tree with 10 nodes<sup>[3]</sup></figcaption>
</figure>

Minimax evalutes all terminal nodes at the maximum search depth `d` and then begins the search process.
The non-terminal nodes' values are determined by the minimizer/maximizer's choices of the descendent leaf nodes.

Referring back to the minmax tree above, the search process begins as follows for a tree with depth 3:

1. `max2` picks the maximum value between v1 and v2
1. `max3` picks the maximum value between v3 and v4
1. `min1` picks the minimum value between `max2` and `max3`
1. Repeat with `max4`, `max5`, and `min2`
1. Finally `max1` (root node) picks the maximum value between `min1` and `min2`

The jist of minimax is that the minimizer and maximizer alternate picking their most optimal value for every level of the tree.

The value at the root node represents the player's maximum gain in a worst-case scenario, **assuming the opponent is always playing their best move.**
Minimax with deep searches (large `d` value) are not optimal against opponents with random actions because the algorithm assumes the opponent is competent.


One last thing to consider is that the algorithm's search time drastically increases for complex games with enormous action spaces, such as chess.
The algorithm visits *every* node - every possible action - before choosing an optimal action.
So the larger and deeper the tree, the longer the search algorithm takes to find the most optimal value.

The search time can be greatly reduced by tuning the search algorithm with a technique call **alpha-beta pruning**.

---
# References/Notes

|     |
| --- |
| [1] Other papers or articles may refer to the player as p<sub>i</sub> or a<sub>i</sub>, and opponent(s) as p<sub>-i</sub> or a<sub>-i</sub> |
| [2] [How the Computer Beat the Go Master](https://www.scientificamerican.com/article/how-the-computer-beat-the-go-master/) |
| [3] [Depth-first search animation](https://en.wikipedia.org/wiki/Depth-first_search#/media/File:Depth-First-Search.gif) |